{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zo_469KCjNO"
      },
      "source": [
        "### Exports for FORGENIUS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iR-vrSQSC9jW"
      },
      "outputs": [],
      "source": [
        "!pip install geemap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WoxsbCyC-8m"
      },
      "outputs": [],
      "source": [
        "!earthengine authenticate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DtmB3ZcDCTH"
      },
      "source": [
        "Import relevant python modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FSl8I2SC_C5"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "ee.Initialize()\n",
        "import geemap\n",
        "Map = geemap.Map()\n",
        "from IPython.display import JSON"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztAQJ6XXP4BX"
      },
      "source": [
        "Load GCU polygons and declare globals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdqQ_h15CjNS"
      },
      "outputs": [],
      "source": [
        "# load forgenius polygons\n",
        "polygons = ee.FeatureCollection('projects/ee-milko/assets/gcu_shapes')\n",
        "\n",
        "# globals\n",
        "###\n",
        "# Note that we now separate GCU information from shapes,\n",
        "# so only the GeometryID will be used as unique identifier\n",
        "# and metadata in properties.\n",
        "###\n",
        "export_folder = 'ForgeniusExport'\n",
        "shape_id = 'GeometryID'\n",
        "unit_id = 'UnitID'\n",
        "gcu_id = 'UnitNumber'\n",
        "\n",
        "###\n",
        "# Europe\n",
        "# Note that it includes Georgia, the Azores Islands and the Canary Islands.\n",
        "###\n",
        "europe = ee.Geometry.MultiPolygon(\n",
        "  [\n",
        "    [\n",
        "\t\t\t[\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t-25.695308647197542,\n",
        "\t\t\t\t\t67.23801112519807\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t-27.14550395969755,\n",
        "\t\t\t\t\t63.898673465352644\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t-20.333980522197542,\n",
        "\t\t\t\t\t62.22693529585702\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t-10.138668022197548,\n",
        "\t\t\t\t\t63.898673465352644\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t-10.885738334697546,\n",
        "\t\t\t\t\t67.1528475956907\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t-19.718746147197546,\n",
        "\t\t\t\t\t67.79259157662841\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t-25.695308647197542,\n",
        "\t\t\t\t\t67.23801112519807\n",
        "\t\t\t\t]\n",
        "\t\t\t]\n",
        "\t\t],\n",
        "\t\t[\n",
        "\t\t\t[\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t25.544925727802454,\n",
        "\t\t\t\t\t73.02255350915792\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t12.31738666530245,\n",
        "\t\t\t\t\t71.41313528514112\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t-10.395820973315923,\n",
        "\t\t\t\t\t63.1549422894266\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t-14.445308647197546,\n",
        "\t\t\t\t\t56.92092561250376\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t-11.918453178447548,\n",
        "\t\t\t\t\t27.039440497919774\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t-8.754390678447548,\n",
        "\t\t\t\t\t25.562147421034734\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t34.75146869655245,\n",
        "\t\t\t\t\t25.997432756878307\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t51.73633197780245,\n",
        "\t\t\t\t\t37.857404237615626\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t51.07024040994158,\n",
        "\t\t\t\t\t40.78364672467574\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t40.87845938095193,\n",
        "\t\t\t\t\t49.75279571510055\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t32.22123281845194,\n",
        "\t\t\t\t\t60.0428385062494\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t34.72611563095193,\n",
        "\t\t\t\t\t72.47523705944548\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t25.544925727802454,\n",
        "\t\t\t\t\t73.02255350915792\n",
        "\t\t\t\t]\n",
        "\t\t\t]\n",
        "\t\t],\n",
        "\t\t[\n",
        "\t\t\t[\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t-10.625446869048067,\n",
        "\t\t\t\t\t71.30075112528307\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t-10.361774994048067,\n",
        "\t\t\t\t\t70.27424567977174\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t-5.5717359315480675,\n",
        "\t\t\t\t\t70.67083792416264\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t-6.7143140565480675,\n",
        "\t\t\t\t\t71.56660006121781\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t-10.625446869048067,\n",
        "\t\t\t\t\t71.30075112528307\n",
        "\t\t\t\t]\n",
        "\t\t\t]\n",
        "\t\t],\n",
        "\t\t[\n",
        "\t\t\t[\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t-31.06358097506254,\n",
        "\t\t\t\t\t41.1772146823826\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t-33.48057316256254,\n",
        "\t\t\t\t\t38.443486969032314\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t-17.00108097506254,\n",
        "\t\t\t\t\t31.23935040308769\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t-14.54014347506254,\n",
        "\t\t\t\t\t33.28302140035009\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t-24.164166912562543,\n",
        "\t\t\t\t\t40.00932248815723\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t-31.06358097506254,\n",
        "\t\t\t\t\t41.1772146823826\n",
        "\t\t\t\t]\n",
        "\t\t\t]\n",
        "\t\t],\n",
        "\t\t[\n",
        "\t\t\t[\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t-19.42731573478265,\n",
        "\t\t\t\t\t29.44294411691417\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t-19.25153448478265,\n",
        "\t\t\t\t\t26.17860766874929\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t-14.94489385978265,\n",
        "\t\t\t\t\t26.572313496293894\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t-13.494698547282649,\n",
        "\t\t\t\t\t28.055982113199935\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t-12.57184698478265,\n",
        "\t\t\t\t\t29.481206483971427\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t-16.08747198478265,\n",
        "\t\t\t\t\t30.129448042603595\n",
        "\t\t\t\t],\n",
        "\t\t\t\t[\n",
        "\t\t\t\t\t-19.42731573478265,\n",
        "\t\t\t\t\t29.44294411691417\n",
        "\t\t\t\t]\n",
        "\t\t\t]\n",
        "\t\t]\n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnlJA2HNlil0"
      },
      "source": [
        "Declare common functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4bKRNLJlpOi"
      },
      "outputs": [],
      "source": [
        "###\n",
        "# Export a descriptor from a feature collection in CSV format on Goofle Drive.\n",
        "#\n",
        "# filename:      Output variable name and filename.\n",
        "# regions:      Features collection.\n",
        "# selectors:    Output columns.\n",
        "###\n",
        "def exportFeatureCollection(filename, regions, selectors):\n",
        "  task = ee.batch.Export.table.toDrive(collection=regions, folder=export_folder, description=filename, fileFormat='CSV', selectors=selectors)\n",
        "  task.start()\n",
        "\n",
        "###\n",
        "# Filter high quality pixels,\n",
        "# select required band,\n",
        "# copy timestamp property to result.\n",
        "#\n",
        "# image:        Image to filter.\n",
        "# qualityBand:  Name of QA band.\n",
        "# dataBand:     Name of data band of interest.\n",
        "###\n",
        "def selectQualityPixels(image, mask, qualityBand, dataBand):\n",
        "    # Select image quality band\n",
        "    qa = image.select(qualityBand)\n",
        "\n",
        "    # Create mask to filter pixels containing clouds\n",
        "    cloudBitMask = mask\n",
        "    mask = qa.bitwiseAnd(cloudBitMask).eq(0)\n",
        "\n",
        "    return image \\\n",
        "            .updateMask(mask) \\\n",
        "            .select(dataBand) \\\n",
        "            .copyProperties(image, ['system:time_start'])\n",
        "\n",
        "###\n",
        "# Aggregate data at monthly resolution.\n",
        "#\n",
        "# year:         Year to aggregate.\n",
        "# multiplier:   Coefficient applied to all values.\n",
        "###\n",
        "def groupByMonth(collection, year, multiplier=1):\n",
        "    months = ee.List.sequence(1, 12, 1)\n",
        "\n",
        "    # Aggregate data by month.\n",
        "    def aggregateByMonth(m):\n",
        "\n",
        "      # Convert month to number.\n",
        "      month = ee.Number(m)\n",
        "\n",
        "      # Filter items in month,\n",
        "      # extract values mean.\n",
        "      monthly = collection.filter(ee.Filter.calendarRange(year, year, 'year')) \\\n",
        "                    .filter(ee.Filter.calendarRange(month, month, 'month')) \\\n",
        "                    .mean()\n",
        "\n",
        "      # Multiply result by coefficient, if latter is not 1.\n",
        "      if multiplier != 1:\n",
        "        monthly = monthly.multiply(multiplier)\n",
        "\n",
        "      # Return image with aggregated value, year, month and timestamp.\n",
        "      return monthly \\\n",
        "          .set('year', year) \\\n",
        "          .set('month', m) \\\n",
        "          .set('system:time_start', ee.Date.fromYMD(year, m, 1).millis())\n",
        "\n",
        "    return months.map(aggregateByMonth)\n",
        "\n",
        "###\n",
        "# Get mean by month for GCU polygons.\n",
        "#\n",
        "# image:        Image to process.\n",
        "# descriptor:   Feature name.\n",
        "# scale:        Resolution scale in meters.\n",
        "###\n",
        "def monthlyRegions(image, descriptor, scale):\n",
        "\n",
        "  def setMonthYear(feature):\n",
        "\n",
        "    # Get year and month.\n",
        "    year = ee.Image(image).get('year')\n",
        "    month = ee.Image(image).get('month')\n",
        "\n",
        "    # Return date feature.\n",
        "    return feature.set({ 'year':year, 'month':month })\n",
        "\n",
        "  # Return regions.\n",
        "  return image.select(descriptor).reduceRegions(collection=polygons, reducer=ee.Reducer.mean().setOutputs([descriptor]), scale=scale).map(setMonthYear)\n",
        "\n",
        "###\n",
        "# Get mean by month for GCU polygons and mark unavailable values.\n",
        "#\n",
        "# image:        Image to process.\n",
        "# descriptor:   Band and feature name.\n",
        "# na:           Value for missing elements.\n",
        "# scale:        Resolution scale in meters.\n",
        "# projection:   Projection.\n",
        "###\n",
        "def zonalStatisticsNa(image, descriptor, na, scale, projection):\n",
        "\n",
        "  def set_NA(feature):\n",
        "\n",
        "    # Get list of non-null descriptor values.\n",
        "    values = ee.List([feature.get(descriptor), na]).reduce(ee.Reducer.firstNonNull())\n",
        "\n",
        "    # Set time frame.\n",
        "    system_time_start = ee.Image(image).get('system:time_start')\n",
        "    year = ee.Image(image).get('year')\n",
        "    month = ee.Image(image).get('month')\n",
        "\n",
        "    # Set metadata and return feature.\n",
        "    return feature.set({descriptor: values, 'imageID': image.id(), 'system:time_start': system_time_start, 'year': year, 'month': month})\n",
        "\n",
        "  return image.reduceRegions(collection=polygons, reducer=ee.Reducer.mean().setOutputs([descriptor]), scale=scale, crs=projection).map(set_NA)\n",
        "\n",
        "# Merge image bands.\n",
        "def mergeImageBands(joinResult):\n",
        "\n",
        "  return ee.Image(joinResult.get('primary')).addBands(joinResult.get('secondary'))\n",
        "\n",
        "# Wrapper function for masking clouds.\n",
        "# Note: this function is not used.\n",
        "def maskClouds(img):\n",
        "\n",
        "  cloudProbabilityThreshold = 40\n",
        "  cloudThresh = 40\n",
        "  cloudMask = img.select('probability').lt(cloudProbabilityThreshold)\n",
        "  img = s2CloudScore(img)\n",
        "\n",
        "  return img.updateMask(cloudMask).updateMask(img.select('cloudScore').lt(cloudThresh))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY20en0lCjNS"
      },
      "source": [
        "### Topography"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8v9Ks0yCjNT"
      },
      "outputs": [],
      "source": [
        "# Load DEM\n",
        "# https://www.eea.europa.eu/data-and-maps/data/copernicus-land-monitoring-service-eu-dem\n",
        "# Version 1.0 or version 1.1?\n",
        "# 40.56GB\n",
        "model = ee.ImageCollection(\"projects/phenology-303215/assets/eu_dem\") \\\n",
        "          .filterBounds(europe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oqvw_zGbBaOl"
      },
      "outputs": [],
      "source": [
        "# elevation\n",
        "descriptor = 'elevation'\n",
        "descriptor_mean = 'elevation_mean'\n",
        "descriptor_stDev = 'elevation_stdDev'\n",
        "# Create combined reducer to get mean and standard deviation.\n",
        "reducer = ee.Reducer.mean().combine(reducer2=ee.Reducer.stdDev(), sharedInputs=True).setOutputs([descriptor_mean, descriptor_stDev])\n",
        "regions = model.median().reduceRegions(collection=polygons, reducer=reducer, scale=25)\n",
        "exportFeatureCollection(filename=descriptor, regions=regions, selectors=[shape_id, descriptor_mean, descriptor_stDev])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQ6q1i8ulez_"
      },
      "outputs": [],
      "source": [
        "# slope\n",
        "descriptor = 'slope'\n",
        "regions = model.map(lambda image: ee.Terrain.slope(image)).median().reduceRegions(collection=polygons, reducer=ee.Reducer.mean().setOutputs([descriptor]), scale=25)\n",
        "exportFeatureCollection(filename=descriptor, regions=regions, selectors=[shape_id, descriptor])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtcZ5EfXmcf8"
      },
      "outputs": [],
      "source": [
        "# aspect\n",
        "descriptor = 'aspect'\n",
        "regions = model.map(lambda image: ee.Terrain.aspect(image)).median().reduceRegions(collection=polygons, reducer=ee.Reducer.mean().setOutputs([descriptor]), scale=25)\n",
        "exportFeatureCollection(filename=descriptor, regions=regions, selectors=[shape_id, descriptor])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIb1R6cyCjNT"
      },
      "source": [
        "### Canopy height"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gZhev5JCjNU"
      },
      "outputs": [],
      "source": [
        "# Set globals\n",
        "year = 2019\n",
        "descriptor = 'canopy_height'\n",
        "filename = 'canopy_height_2019'\n",
        "\n",
        "# load collection\n",
        "# https://glad.umd.edu/dataset/gedi\n",
        "model = ee.ImageCollection('users/potapovpeter/GEDI_V27') \\\n",
        "          .filterBounds(europe) \\\n",
        "          .mosaic()\n",
        "\n",
        "# add date to feature polygons\n",
        "collection = polygons.map(lambda feature: feature.set({ 'year': year }))\n",
        "\n",
        "# apply reducer\n",
        "regions = model.reduceRegions(collection=collection, reducer=ee.Reducer.mean().setOutputs([descriptor]), scale = 30)\n",
        "\n",
        "# export results\n",
        "exportFeatureCollection(filename=filename, regions=regions, selectors=[shape_id, 'year', descriptor])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdfQ65zoCjNU"
      },
      "source": [
        "### Dominant leaf type\n",
        "https://code.earthengine.google.com/96720d5eac7e9db1de8e87c8cd7dd162\n",
        "\n",
        "https://land.copernicus.eu/pan-european/high-resolution-layers/forests/dominant-leaf-type/status-maps/dominant-leaf-type-2018"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eRt_BrHCjNU"
      },
      "outputs": [],
      "source": [
        "# Set globals\n",
        "year = 2018\n",
        "descriptor = 'dominant_forest_type'\n",
        "filename = 'dominant_leaf_type'\n",
        "\n",
        "# Load image and skip empty pixels.\n",
        "model = ee.Image('users/marcogirardello/forgenius/domleaftypeeu')\n",
        "model = model.updateMask(model.gt(0))\n",
        "\n",
        "# add date to feature polygons\n",
        "collection = polygons.map(lambda feature: feature.set({ 'year': year }))\n",
        "\n",
        "# apply reducer (mode)\n",
        "regions = model.reduceRegions(collection=collection, reducer=ee.Reducer.mode().setOutputs([descriptor]), scale=12, crs='EPSG:4326')\n",
        "\n",
        "# export results\n",
        "exportFeatureCollection(filename=descriptor, regions=regions, selectors=[shape_id, 'year', descriptor])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMZsQgGnCjNb"
      },
      "source": [
        "### Biomass for the year 2010\n",
        "https://climate.esa.int/en/projects/biomass/data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bqmf9AQXYkA7"
      },
      "outputs": [],
      "source": [
        "# Set globals\n",
        "year = 2010\n",
        "descriptor = 'biomass_2010'\n",
        "filename = 'biomass_2010'\n",
        "\n",
        "# load collection\n",
        "# https://climate.esa.int/en/projects/biomass/data/\n",
        "model = ee.Image(\"users/guidolavespa2511/EU_biomass\")\n",
        "\n",
        "# add date to feature polygons\n",
        "collection = polygons.map(lambda feature: feature.set({ 'year': year }))\n",
        "\n",
        "# apply reducer\n",
        "regions = model.reduceRegions(collection=collection, reducer=ee.Reducer.mean().setOutputs([descriptor]), scale = 98.95114197446169, crs='EPSG:4326')\n",
        "\n",
        "# export results\n",
        "exportFeatureCollection(filename=descriptor, regions=regions, selectors=[shape_id, 'year', descriptor])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIC1dcMpCjNV"
      },
      "source": [
        "## Monthly Day Land surface temperature (LST). Data are from terra, meaning that the satellite passes in the morning.\n",
        "#### Catalogue entry https://developers.google.com/earth-engine/datasets/catalog/MODIS_006_MOD11A2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmPdgaviCjNV"
      },
      "outputs": [],
      "source": [
        "# Set references\n",
        "descriptor = 'LST_Day_1km'\n",
        "startDate = '2000-01-01'\n",
        "endDate = '2023-12-31'\n",
        "dataBand = 'LST_Day_1km'\n",
        "qualityBand = 'QC_Day'\n",
        "\n",
        "# Filter image collection by:\n",
        "# selecting Europe bounds,\n",
        "# selecting years 2000 to 2021,\n",
        "# select quality and data bands,\n",
        "# select only good quality pixels.\n",
        "collection = ee.ImageCollection(\"MODIS/061/MOD11A2\") \\\n",
        "        .filterBounds(europe) \\\n",
        "        .filter(ee.Filter.date(startDate, endDate)) \\\n",
        "        .select([dataBand, qualityBand]) \\\n",
        "        .map(lambda image: selectQualityPixels(image=image, mask=(0 << 0), qualityBand=qualityBand, dataBand=dataBand))\n",
        "\n",
        "# Aggregate data by year and month.\n",
        "years = ee.List.sequence(2001, 2021, 1)\n",
        "monthlyCollection = ee.ImageCollection.fromImages(years.map(lambda year: groupByMonth(collection=collection, year=year, multiplier=0.02)).flatten())\n",
        "\n",
        "# Apply zonal statistics reducer.\n",
        "regions = monthlyCollection.map(lambda image: zonalStatisticsNa(image=image, descriptor=descriptor, na=-9999, scale=926.6254330555, projection='SR-ORG:6974')).flatten()\n",
        "\n",
        "# export results\n",
        "exportFeatureCollection(filename=descriptor, regions=regions, selectors=[shape_id, 'year', 'month', descriptor])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__H7Jh_HCjNX"
      },
      "source": [
        "### Leaf Area Index (LAI) (monthly)\n",
        "\n",
        "#### Catalogue entry https://developers.google.com/earth-engine/datasets/catalog/MODIS_006_MOD15A2H?hl=en\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnK-kosan8_v"
      },
      "outputs": [],
      "source": [
        "# Set references\n",
        "descriptor = 'Lai_500m'\n",
        "startDate = '2003-01-01'\n",
        "endDate = '2023-12-31'\n",
        "dataBand = 'Lai_500m'\n",
        "qualityBand = 'FparLai_QC'\n",
        "\n",
        "# Filter image collection by:\n",
        "# selecting Europe bounds,\n",
        "# selecting years 2000 to 2021,\n",
        "# select quality and data bands,\n",
        "# select only good quality pixels.\n",
        "#https://gis.stackexchange.com/questions/376972/time-series-extraction-of-modis-lai-product-every-3-days-a-new-satellite-image\n",
        "collection = ee.ImageCollection(\"MODIS/061/MOD15A2H\") \\\n",
        "        .filterBounds(europe) \\\n",
        "        .filter(ee.Filter.date(startDate, endDate)) \\\n",
        "        .select([dataBand, qualityBand]) \\\n",
        "        .map(lambda image: selectQualityPixels(image=image, mask=(1 << 0), qualityBand=qualityBand, dataBand=dataBand))\n",
        "\n",
        "# Aggregate data by year and month.\n",
        "years = ee.List.sequence(2003, 2021, 1)\n",
        "monthlyCollection = ee.ImageCollection.fromImages(years.map(lambda year: groupByMonth(collection=collection, year=year, multiplier=0.1)).flatten())\n",
        "\n",
        "# check this bit as it does not work. year need changing (2024)\n",
        "#test1 = monthlyCollection.filter(ee.Filter.listContains('system:band_names','Lai_500m'))\n",
        "\n",
        "# Apply zonal statistics reducer.\n",
        "regions = monthlyCollection.map(lambda image: zonalStatisticsNa(image=image, descriptor=descriptor, na=-9999, scale=463.3127165275, projection='SR-ORG:6974')).flatten()\n",
        "\n",
        "# export results\n",
        "exportFeatureCollection(filename=descriptor, regions=regions, selectors=[shape_id, 'year', 'month', descriptor])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaAd_LpZCjNZ"
      },
      "source": [
        "### GPP (monthly)\n",
        "#### Catalogue entry https://developers.google.com/earth-engine/datasets/catalog/MODIS_006_MYD17A2H?hl=en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8LWqRX3JVvG"
      },
      "outputs": [],
      "source": [
        "# Set references\n",
        "descriptor = 'Gpp'\n",
        "start_year = 2021\n",
        "# startDate = '2003-01-01'\n",
        "startDate = '2021-01-01'\n",
        "end_year = 2023\n",
        "# endDate = '2021-12-31'\n",
        "endDate = '2023-08-05'\n",
        "dataBand = 'Gpp'\n",
        "qualityBand = 'Psn_QC'\n",
        "\n",
        "# Filter image collection by:\n",
        "# selecting Europe bounds,\n",
        "# selecting years 2000 to 2021,\n",
        "# select quality and data bands,\n",
        "# select only good quality pixels.\n",
        "collection = ee.ImageCollection(\"MODIS/061/MYD17A2H\") \\\n",
        "        .filterBounds(europe) \\\n",
        "        .filter(ee.Filter.date(startDate, endDate)) \\\n",
        "        .select([dataBand, qualityBand]) \\\n",
        "        .map(lambda image: selectQualityPixels(image=image, mask=(1 << 0), qualityBand=qualityBand, dataBand=dataBand))\n",
        "\n",
        "# Aggregate data by year and month.\n",
        "years = ee.List.sequence(start_year, end_year, 1)\n",
        "monthlyCollection = ee.ImageCollection.fromImages(years.map(lambda year: groupByMonth(collection=collection, year=year, multiplier=0.0001)).flatten())\n",
        "\n",
        "# Apply zonal statistics reducer.\n",
        "regions = monthlyCollection.map(lambda image: zonalStatisticsNa(image=image, descriptor=descriptor, na=-9999, scale=463.3127165275, projection='SR-ORG:6974')).flatten()\n",
        "\n",
        "# export results\n",
        "exportFeatureCollection(filename=descriptor, regions=regions, selectors=[shape_id, 'year', 'month', descriptor])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLnvIUVhCjNj"
      },
      "source": [
        "### NDVI from Sentinel 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCmMUb2JCjNj"
      },
      "source": [
        "#### Guido's original code https://code.earthengine.google.com/8efacef6da5c9cfcfffcecfb0027190c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eb3itv1ThKCA"
      },
      "outputs": [],
      "source": [
        "# Set references\n",
        "descriptor = 'ndvi'\n",
        "filename = 'ndvi'\n",
        "startDate = '2016-01-01'\n",
        "endDate = '2021-12-31'\n",
        "originalBandNames = ['QA60', 'B1','B2','B3','B4','B5','B6','B7','B8','B8A', 'B9','B10', 'B11','B12','probability']\n",
        "renamedBandNames  = ['QA60','cb', 'blue', 'green', 'red', 're1','re2','re3','nir', 'nir2', 'waterVapor', 'cirrus','swir1', 'swir2','probability']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qteq26uGipxB"
      },
      "outputs": [],
      "source": [
        "# Local functions\n",
        "\n",
        "# function for calculating and adding NDVI to the provided image.\n",
        "def s2AddNDVI(img):\n",
        "\n",
        "  ndvi = img.normalizedDifference(['B8','B4']).multiply(1000).rename(descriptor)\n",
        "\n",
        "  return img.addBands(ndvi)\n",
        "\n",
        "def rescale(img, exp, thresholds):\n",
        "\n",
        "  return img.expression(exp, {'img': img}).subtract(thresholds[0]).divide(thresholds[1] - thresholds[0])\n",
        "\n",
        "# function for cloudscoring\n",
        "def s2CloudScore(img):\n",
        "\n",
        "  # Compute several indicators of cloudyness and take the minimum of them.\n",
        "  score = ee.Image(1)\n",
        "\n",
        "  # Clouds are reasonably bright in the blue and cirrus bands.\n",
        "  score = score.min(rescale(img, 'img.blue', [0.1, 0.5]))\n",
        "  score = score.min(rescale(img, 'img.cb', [0.1, 0.3]))\n",
        "  score = score.min(rescale(img, 'img.cb + img.cirrus', [0.15, 0.2]))\n",
        "\n",
        "  # Clouds are reasonably bright in all visible bands.\n",
        "  score = score.min(rescale(img, 'img.red + img.green + img.blue', [0.2, 0.8]))\n",
        "\n",
        "  # Clouds are moist\n",
        "  ndmi = img.normalizedDifference(['nir','swir1'])\n",
        "  score=score.min(rescale(ndmi, 'img', [-0.1, 0.1]))\n",
        "\n",
        "  # However, clouds are not snow\n",
        "  ndsi = img.normalizedDifference(['green', 'swir1'])\n",
        "  score=score.min(rescale(ndsi, 'img', [0.8, 0.6]))\n",
        "  score = score.multiply(100).byte()\n",
        "\n",
        "  return img.addBands(score.rename('cloudScore'))\n",
        "\n",
        "# function to mask clouds using the Sentinel-2 QA band\n",
        "def s2MaskClouds(img):\n",
        "  qa = img.select('QA60').int16()\n",
        "\n",
        "  # bits 10 and 11 are cloud and cirrus, respectively\n",
        "  cloudBitMask = 1 << 10\n",
        "  cirrusBitMask = 1 << 11\n",
        "\n",
        "  # both flags should be set to zero, indicating clear conditions\n",
        "  mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask))\n",
        "\n",
        "  # return the masked and scaled data\n",
        "  return img.updateMask(mask).copyProperties(img,['system:time_start'])\n",
        "\n",
        "# Divide all values by coefficient,\n",
        "# add cloud probability bands\n",
        "# and add image timestamp.\n",
        "def s2CleanImage(img):\n",
        "\n",
        "  # rescale 0-1\n",
        "  t = img.select([ 'B1','B2','B3','B4','B5','B6','B7', 'B8','B8A', 'B9','B10', 'B11','B12']).divide(10000)\n",
        "\n",
        "  # add QA60 and probability bands\n",
        "  t = t.addBands(img.select(['QA60', 'probability']))\n",
        "  out = t.copyProperties(img).copyProperties(img, ['system:time_start'])\n",
        "\n",
        "  return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pARN1ivGCjNj"
      },
      "outputs": [],
      "source": [
        "# Load Sentinel 2 data and clouds\n",
        "sentinelData = ee.ImageCollection('COPERNICUS/S2').filterBounds(europe).filterDate(startDate, endDate)\n",
        "sentinelCloud = ee.ImageCollection(\"COPERNICUS/S2_CLOUD_PROBABILITY\").filterBounds(europe).filterDate(startDate, endDate)\n",
        "\n",
        "# Join data and clouds by image index.\n",
        "innerjoined = ee.Join.inner() \\\n",
        "             .apply(primary = sentinelData,\n",
        "                    secondary = sentinelCloud,\n",
        "                    condition = ee.Filter.equals(leftField = 'system:index',\n",
        "                                                  rightField = 'system:index'))\n",
        "\n",
        "# Merge joined collections.\n",
        "newCollection = ee.ImageCollection(innerjoined.map(mergeImageBands))\n",
        "\n",
        "# Rename bands.\n",
        "newCollection1 = newCollection.map(s2CleanImage).select(originalBandNames, renamedBandNames)\n",
        "\n",
        "# Filter cloudy images and restore original band names.\n",
        "newCollection2 = newCollection1.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 80)) \\\n",
        "              .map(s2MaskClouds) \\\n",
        "              .select( renamedBandNames, originalBandNames) \\\n",
        "              .map(s2AddNDVI) \\\n",
        "              .select(descriptor)\n",
        "\n",
        "# aggregate to a monthly resolution\n",
        "years = ee.List.sequence(2016, 2021, 1)\n",
        "monthlyCollection = ee.ImageCollection.fromImages(years.map(lambda year: groupByMonth(collection=newCollection2, year=year)).flatten())\n",
        "\n",
        "# Apply zonal statistics reducer.\n",
        "regions = monthlyCollection.map(lambda image: monthlyRegions(image=image, descriptor=descriptor, scale=10)).flatten()\n",
        "\n",
        "# export results\n",
        "exportFeatureCollection(filename=filename, regions=regions, selectors=[shape_id, 'year', 'month', descriptor])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn8PWInqCjNn"
      },
      "source": [
        "### NDWI\n",
        "#### Catalogue entry https://developers.google.com/earth-engine/datasets/catalog/MODIS_MCD43A4_006_NDWI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7n9L-zdZcm4"
      },
      "outputs": [],
      "source": [
        "# Set references\n",
        "descriptor = 'NDWI'\n",
        "startDate = '2001-01-01'\n",
        "endDate = '2023-12-31'\n",
        "\n",
        "# Filter image collection by:\n",
        "# selecting Europe bounds,\n",
        "# selecting years 2001 to 2021,\n",
        "# select quality and data bands,\n",
        "# select only good quality pixels.\n",
        "collection = ee.ImageCollection(\"MODIS/MCD43A4_006_NDWI\") \\\n",
        "        .filterBounds(europe) \\\n",
        "        .filter(ee.Filter.date(startDate, endDate))\n",
        "\n",
        "# Aggregate data by year and month.\n",
        "years = ee.List.sequence(2003, 2021, 1)\n",
        "monthlyCollection = ee.ImageCollection.fromImages(years.map(lambda year: groupByMonth(collection=collection, year=year)).flatten())\n",
        "\n",
        "# Apply zonal statistics reducer.\n",
        "regions = monthlyCollection.map(lambda image: zonalStatisticsNa(image=image, descriptor=descriptor, na=-9999, scale=463.3127165275, projection='SR-ORG:6974')).flatten()\n",
        "\n",
        "# export results\n",
        "exportFeatureCollection(filename=descriptor, regions=regions, selectors=[shape_id, 'year', 'month', descriptor])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCvt4NrQCjNo"
      },
      "source": [
        "### Land cover 10 m\n",
        "#### Data source: https://www.esa.int/ESA_Multimedia/Images/2020/03/Europe_land-cover_mapped_in_10_m_resolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8sxxFzRCjNp"
      },
      "source": [
        "Skip this one!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ww3C5HP8CjNp"
      },
      "outputs": [],
      "source": [
        "#eulandcover = ee.Image('users/marcogirardello12/forgenius/eulandcover10m')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d57MIYdGCjNp"
      },
      "source": [
        "### ERA5 Land"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOfgi11FA7uk"
      },
      "outputs": [],
      "source": [
        "# Load ERA5 image collection.\n",
        "era5Collection = ee.ImageCollection(\"ECMWF/ERA5_LAND/HOURLY\").filterBounds(europe)\n",
        "\n",
        "\n",
        "###\n",
        "# Get mean by day for GCU polygons.\n",
        "#\n",
        "# image:        Image to process.\n",
        "# scale:        Resolution scale in meters.\n",
        "# projection:   Image and geometry projection.\n",
        "###\n",
        "def dailyRegions(image, descriptor, scale, projection):\n",
        "\n",
        "  # Aggregate means of GCUs and add year and day to features.\n",
        "   return image.reduceRegions(collection=polygons, reducer=ee.Reducer.mean().setOutputs([descriptor]), scale=scale, crs=projection) \\\n",
        "          .map(lambda feature: feature.set({ 'year': image.get('year'), 'day': image.get('day') }))\n",
        "\n",
        "###\n",
        "# Calculate wind speed.\n",
        "# U component is positive for a west to east flow (eastward wind)\n",
        "# and the V component is positive for south to north flow (northward wind).\n",
        "###\n",
        "def windSpeed(image):\n",
        "\n",
        "  # Select eastward and northward components and return wind speed and copy timestamp.\n",
        "  return image.select(['u_component_of_wind_10m', 'v_component_of_wind_10m']) \\\n",
        "          .pow(2) \\\n",
        "          .reduce(ee.Reducer.sum()) \\\n",
        "          .sqrt() \\\n",
        "          .copyProperties(image, ['system:time_start'])\n",
        "\n",
        "###\n",
        "# Calculate relative humidity.\n",
        "# Calculate using dew point.\n",
        "###\n",
        "def relativeHumidity(img):\n",
        "  img1 = img.subtract(273.15)\n",
        "  rh = ee.Image(100)\\\n",
        "          .subtract(img1.select('temperature_2m').subtract(img1.select('dewpoint_temperature_2m')) \\\n",
        "          .multiply(5)) \\\n",
        "          .select(['constant'],['relative_humidity']) \\\n",
        "          .copyProperties(img,['system:time_start'])\n",
        "  return(rh)\n",
        "\n",
        "###\n",
        "# Calculate daily statistics,\n",
        "###\n",
        "def statsByDay(descriptor, band, prefix, startYear, endYear, scale, projection):\n",
        "\n",
        "  # Iterate time interval years.\n",
        "  for i in range(startYear, endYear):\n",
        "\n",
        "    # Select start and end string dates of the focal year,\n",
        "    fyear_start = ee.Date(str(i) + '-01-01')\n",
        "    fyear_end = ee.Date(str(i) + '-12-31')\n",
        "\n",
        "    # select band\n",
        "    data = era5Collection.select(band).filter(ee.Filter.date(fyear_start, fyear_end))\n",
        "\n",
        "    # days for focal year (based on collection size)\n",
        "    days = ee.List.sequence(start=1, end=fyear_end.difference(fyear_start, 'days'), step=1)\n",
        "\n",
        "    # mean daily value\n",
        "    mean = ee.ImageCollection(days.map(lambda inday: data.filter(ee.Filter.calendarRange(inday, inday, 'day_of_year')).mean().set('year', i).set('day', ee.Number.int(inday))))\n",
        "    regions = mean.map(lambda image: dailyRegions(image=image, descriptor=descriptor, scale=scale, projection=projection)).flatten()\n",
        "\n",
        "    # export final table\n",
        "    task = ee.batch.Export.table.toDrive(collection=regions,\n",
        "                                         folder=export_folder,\n",
        "                                         fileFormat='CSV',\n",
        "                                         description=prefix + str(i),\n",
        "                                         selectors=[shape_id, 'year', 'day', descriptor])\n",
        "    task.start()\n",
        "\n",
        "###\n",
        "# Calculate relative humidity daily statistics,\n",
        "###\n",
        "def humidStatsByDay(descriptor, prefix, startYear, endYear, scale, projection):\n",
        "\n",
        "  # Iterate time interval years.\n",
        "  for i in range(startYear, endYear):\n",
        "\n",
        "    # Select start and end string dates of the focal year,\n",
        "    fyear_start = ee.Date(str(i) + '-01-01')\n",
        "    fyear_end = ee.Date(str(i) + '-12-31')\n",
        "\n",
        "    # select bands\n",
        "    data = era5Collection.select(['temperature_2m','dewpoint_temperature_2m']).filter(ee.Filter.date(fyear_start, fyear_end)).map(relativeHumidity)\n",
        "\n",
        "    # days for focal year (based on collection size)\n",
        "    days = ee.List.sequence(start=1, end=fyear_end.difference(fyear_start, 'days'), step=1)\n",
        "\n",
        "    # mean daily value\n",
        "    mean = ee.ImageCollection(days.map(lambda inday: data.filter(ee.Filter.calendarRange(inday, inday, 'day_of_year')).mean().set('year', i).set('day', ee.Number.int(inday))))\n",
        "    regions = mean.map(lambda image: dailyRegions(image=image, descriptor=descriptor, scale=scale, projection=projection)).flatten()\n",
        "\n",
        "    # export final table\n",
        "    task = ee.batch.Export.table.toDrive(collection=regions,\n",
        "                                         folder=export_folder,\n",
        "                                         fileFormat='CSV',\n",
        "                                         description=prefix + str(i),\n",
        "                                         selectors=[shape_id, 'year', 'day', descriptor])\n",
        "    task.start()\n",
        "\n",
        "###\n",
        "# Calculate hourly statistics,\n",
        "###\n",
        "def statsByHour(descriptor, band, prefix, startYear, endYear, scale, projection):\n",
        "\n",
        "  # Iterate time interval years.\n",
        "  for i in range(startYear, endYear):\n",
        "\n",
        "    # Select start and end string dates of the focal year, note the shift in dates\n",
        "    fyear_start = ee.Date(str(i) + '-01-02')\n",
        "    fyear_end = ee.Date(str(i+1) + '-01-01')\n",
        "\n",
        "    # Select precipitation from collection,\n",
        "    # filter for period of interest,\n",
        "    # select cumulated precipitation,\n",
        "    # multiply by 1000 and insert year and day (one day before because of shift in dates).\n",
        "    data = era5Collection \\\n",
        "            .select(band) \\\n",
        "            .filter(ee.Filter.date(fyear_start, fyear_end)) \\\n",
        "            .filterMetadata('hour', 'equals', 0) \\\n",
        "            .map(lambda img: img.multiply(1000).set('year', i).set('day', ee.Date(img.get('system:time_start')).advance(-1, 'day').format('D')))\n",
        "\n",
        "    # Extract means for regions.\n",
        "    regions = data.map(lambda image: dailyRegions(image=image, descriptor=descriptor, scale=scale, projection=projection)).flatten()\n",
        "\n",
        "    # export final table\n",
        "    task = ee.batch.Export.table.toDrive(collection=regions,\n",
        "                                         folder=export_folder,\n",
        "                                         fileFormat='CSV',\n",
        "                                         description=prefix + str(i),\n",
        "                                         selectors=[shape_id, 'year', 'day', descriptor])\n",
        "    task.start()\n",
        "\n",
        "###\n",
        "# Calculate wind daily statistics,\n",
        "###\n",
        "def statsWindByDay(descriptor, prefix, startYear, endYear, scale, projection):\n",
        "\n",
        "  # Iterate time interval years.\n",
        "  for i in range(startYear, endYear):\n",
        "\n",
        "    # Select start and end string dates of the focal year,\n",
        "    fyear_start = ee.Date(str(i) + '-01-01')\n",
        "    fyear_end = ee.Date(str(i) + '-12-31')\n",
        "\n",
        "    # Select band and calculate wind speed.\n",
        "    data = era5Collection.filter(ee.Filter.date(fyear_start, fyear_end)).map(windSpeed)\n",
        "\n",
        "    # days for focal year (based on collection size)\n",
        "    days = ee.List.sequence(start=1, end=fyear_end.difference(fyear_start, 'days'), step=1)\n",
        "\n",
        "    # mean daily value\n",
        "    mean = ee.ImageCollection(days.map(lambda inday: data.filter(ee.Filter.calendarRange(inday, inday, 'day_of_year')).mean().set('year', i).set('day', inday)))\n",
        "    regions = mean.map(lambda image: dailyRegions(image=image, descriptor=descriptor, scale=scale, projection=projection)).flatten()\n",
        "\n",
        "    # export final table\n",
        "    task = ee.batch.Export.table.toDrive(collection=regions,\n",
        "                                         folder=export_folder,\n",
        "                                         fileFormat='CSV',\n",
        "                                         description=prefix + str(i),\n",
        "                                         selectors=[shape_id, 'year', 'day', descriptor])\n",
        "    task.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnGjIhrmgvnu"
      },
      "outputs": [],
      "source": [
        "# ERA 5 Globals.\n",
        "startYear = 2000\n",
        "endYear = 2023\n",
        "scale = 1000\n",
        "projection = 'EPSG:4326'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQM8ijO_CjNp"
      },
      "source": [
        "#### Temperature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5w3ar4gsCjNp"
      },
      "outputs": [],
      "source": [
        "# Set locals.\n",
        "band = 'temperature_2m'\n",
        "descriptor = 'temperature_2m'\n",
        "prefix = 'temperature_2m_'\n",
        "\n",
        "# Get daily statistics.\n",
        "statsByDay(descriptor=descriptor, band=band, prefix=prefix, startYear=startYear, endYear=endYear, scale=scale, projection=projection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhGc8CdXCjNq"
      },
      "source": [
        "#### Precipitation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uV7uXYd3hWgo"
      },
      "outputs": [],
      "source": [
        "# Set locals.\n",
        "descriptor = 'total_precipitation'\n",
        "band = 'total_precipitation'\n",
        "prefix = 'total_precipitation_'\n",
        "\n",
        "# Get daily statistics.\n",
        "statsByHour(descriptor=descriptor, band=band, prefix=prefix, startYear=startYear, endYear=endYear, scale=scale, projection=projection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwLD45kaCjNq"
      },
      "source": [
        "#### Wind\n",
        "The meteorological convention for winds is that U component is positive for a west to east flow (eastward wind) and the V component is positive for south to north flow\n",
        "(northward wind).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3DfZGwI0wqs"
      },
      "outputs": [],
      "source": [
        "# Set globals.\n",
        "descriptor = 'wind_speed'\n",
        "prefix = 'wind_speed_'\n",
        "projection = 'EPSG:4326'\n",
        "\n",
        "# Get daily statistics from hourly data.\n",
        "statsWindByDay(descriptor=descriptor, prefix=prefix, startYear=startYear, endYear=endYear, scale=scale, projection=projection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wanVzjI8CjNq"
      },
      "source": [
        "### Soil water content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MutZy-jt8gFB"
      },
      "outputs": [],
      "source": [
        "# layer 1 Layer 1: 0 - 7cm\n",
        "descriptor = 'soil_water_0_7cm'\n",
        "band = 'volumetric_soil_water_layer_1'\n",
        "prefix = 'soil_water_7cm_'\n",
        "statsByDay(descriptor=descriptor, band=band, prefix=prefix, startYear=startYear, endYear=endYear, scale=scale, projection=projection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzsS9ew49Lit"
      },
      "outputs": [],
      "source": [
        "# Layer 2: 7 - 28cm\n",
        "descriptor = 'soil_water_7_28cm'\n",
        "band = 'volumetric_soil_water_layer_2'\n",
        "prefix = 'soil_water_28cm_'\n",
        "statsByDay(descriptor=descriptor, band=band, prefix=prefix, startYear=startYear, endYear=endYear, scale=scale, projection=projection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPaDiWLt9ZRR"
      },
      "outputs": [],
      "source": [
        "# Layer 3: 28 - 100cm\n",
        "descriptor = 'soil_water_28_100cm'\n",
        "band = 'volumetric_soil_water_layer_3'\n",
        "prefix = 'soil_water_100cm_'\n",
        "statsByDay(descriptor=descriptor, band=band, prefix=prefix, startYear=startYear, endYear=endYear, scale=scale, projection=projection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dV2L8NH-X7x"
      },
      "outputs": [],
      "source": [
        "# Layer 4: 100 - 289cm\n",
        "descriptor = 'soil_water_100_289cm'\n",
        "band = 'volumetric_soil_water_layer_4'\n",
        "prefix = 'soil_water_289cm_'\n",
        "statsByDay(descriptor=descriptor, band=band, prefix=prefix, startYear=startYear, endYear=endYear, scale=scale, projection=projection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc4VEUEsCjNr"
      },
      "source": [
        "### Soil temperature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xg4H-yIweEUQ"
      },
      "outputs": [],
      "source": [
        "# Layer 1: 0 - 7cm\n",
        "descriptor = 'soil_temperature_0_7cm'\n",
        "band = 'soil_temperature_level_1'\n",
        "prefix = 'soil_temperature_7cm_'\n",
        "statsByDay(descriptor=descriptor, band=band, prefix=prefix, startYear=startYear, endYear=endYear, scale=scale, projection=projection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dwj0qFYo2e7b"
      },
      "outputs": [],
      "source": [
        "# Layer 2: 7 - 28cm\n",
        "descriptor = 'soil_temperature_7_28cm'\n",
        "band = 'soil_temperature_level_2'\n",
        "prefix = 'soil_temperature_28cm_'\n",
        "statsByDay(descriptor=descriptor, band=band, prefix=prefix, startYear=startYear, endYear=endYear, scale=scale, projection=projection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVlCRwVj26J0"
      },
      "outputs": [],
      "source": [
        "# Layer 3: 28 - 100cm\n",
        "descriptor = 'soil_temperature_28_100cm'\n",
        "band = 'soil_temperature_level_3'\n",
        "prefix = 'soil_temperature_100cm_'\n",
        "statsByDay(descriptor=descriptor, band=band, prefix=prefix, startYear=startYear, endYear=endYear, scale=scale, projection=projection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGT8Nfk53HXK"
      },
      "outputs": [],
      "source": [
        "# Layer 4: 100 - 289cm\n",
        "descriptor = 'soil_temperature_100_289cm'\n",
        "band = 'soil_temperature_level_4'\n",
        "prefix = 'soil_temperature_289cm_'\n",
        "statsByDay(descriptor=descriptor, band=band, prefix=prefix, startYear=startYear, endYear=endYear, scale=scale, projection=projection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrlNPxyKCjNr"
      },
      "source": [
        "### Latent heat flux\n",
        "surface_latent_heat_flux\tJ/m2\n",
        "Exchange of latent heat with the surface through turbulent diffusion. This variables is accumulated from the beginning of the forecast time to the end of the forecast step. By model convention, downward fluxes are positive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNXGIbungIiI"
      },
      "outputs": [],
      "source": [
        "# Latent heat flux.\n",
        "descriptor = 'surface_latent_heat_flux'\n",
        "band = 'surface_latent_heat_flux'\n",
        "prefix = 'latent_heat_flux'\n",
        "statsByDay(descriptor=descriptor, band=band, prefix=prefix, startYear=startYear, endYear=endYear, scale=scale, projection=projection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VWHIkeqCjNs"
      },
      "source": [
        "### Incoming solar radiation\n",
        "surface_net_solar_radiation\tJ/m2\n",
        "Amount of solar radiation (also known as shortwave radiation) reaching the surface of the Earth (both direct and diffuse) minus the amount reflected by the Earth's surface (which is governed by the albedo).Radiation from the Sun (solar, or shortwave, radiation) is partly reflected back to space by clouds and particles in the atmosphere (aerosols) and some of it is absorbed. The rest is incident on the Earth's surface, where some of it is reflected. The difference between downward and reflected solar radiation is the surface net solar radiation. This variable is accumulated from the beginning of the forecast time to the end of the forecast step. The units are joules per square metre (J m-2). To convert to watts per square metre (W m-2), the accumulated values should be divided by the accumulation period expressed in seconds. The ECMWF convention for vertical fluxes is positive downwards.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aswyIn28jMMQ"
      },
      "outputs": [],
      "source": [
        "# Incoming solar radiation.\n",
        "descriptor = 'surface_net_solar_radiation'\n",
        "band = 'surface_net_solar_radiation'\n",
        "prefix = 'incoming_solar_radiation'\n",
        "statsByDay(descriptor=descriptor, band=band, prefix=prefix, startYear=startYear, endYear=endYear, scale=scale, projection=projection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRRTjwwwCjNs"
      },
      "source": [
        "### Relative humidity\n",
        "Formula from https://en.wikipedia.org/wiki/Dew_point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9S5DvMIYaYA4"
      },
      "outputs": [],
      "source": [
        "# Relative humidity.\n",
        "descriptor = 'relative_humidity'\n",
        "prefix = 'relative_humidity'\n",
        "humidStatsByDay(descriptor=descriptor, prefix=prefix, startYear=startYear, endYear=endYear, scale=scale, projection=projection)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}